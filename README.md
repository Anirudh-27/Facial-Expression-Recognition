# Facial Expression Recognition

### :busts_in_silhouette: The Team
* Dr. Jabez C. Christopher
* Anirudh Bhupalarao

### :cd: Dataset
* FER2013: The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).

### :key: Run the Code
* Save files and make a directory as shown.
* Open the preprocessing folder and run the notebooks after placing the images in the google drive. This will finish the preprocessing of the images and make them ready for passing into the model. To run the preprocessing codes, you have to download the shape_predictor_68_face_landmarks.dat file from the internet.
* Then run the model codes with the processed images.

### :books: Libraries Used
* Numpys
* Pandas
* Keras
* CV2
* Tensorflow
* sklearn
* matplotlib

### :star: Output
* View results sheet to see detailed results for different parameters like epochs, learning rates, decay etc.

### For more information please refer to the project report in the repository.
